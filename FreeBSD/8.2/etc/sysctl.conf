# $FreeBSD: src/etc/sysctl.conf,v 1.8.38.1 2010/12/21 17:10:29 kensmith Exp $
#
#  This file is read when going to multi-user and its contents piped thru
#  ``sysctl'' to adjust kernel values.  ``man 5 sysctl.conf'' for details.
#

security.bsd.see_other_uids=0
security.bsd.see_other_gids=0
# No zero mapping feature
security.bsd.map_at_zero=0
# Allow to use System V IPC in jail
security.jail.sysvipc_allowed=1

net.inet.ip.accept_sourceroute=0
# max size of the IP input queue
net.inet.ip.intr_queue_maxlen=8192
#net.inet.ip.fastforwarding=1
net.inet.ip.portrange.first=32768
net.inet.ip.portrange.last=65535
net.inet.ip.redirect=0
net.inet.ip.random_id=1
net.inet.ip.sourceroute=0
net.inet.ip.ttl=128
# ipfw
net.inet.ip.fw.dyn_max=65536
net.inet.ip.fw.verbose=1

kern.corefile=/var/tmp/%U.%N.%P.core
#
kern.maxfiles=131072
kern.maxvnodes=131072
kern.maxfilesperproc=16384
#
kern.maxproc=16384
kern.threads.max_threads_per_proc=4096
kern.maxprocperuid=8192
kern.timecounter.hardware=TSC
#kern.timecounter.hardware=ACPI-fast

# max. backlog size
kern.ipc.somaxconn=4096

# sockets
kern.ipc.maxsockets=131072
# maximum socket buffer size (32Mb)
kern.ipc.maxsockbuf=33554432
# Maximum number of mbuf page size jumbo clusters allowed
kern.ipc.nmbjumbop=32768

# System V shared memory
kern.ipc.shmmax=134217728
kern.ipc.shmall=65536
# Enable locking of shared memory pages in core
kern.ipc.shm_use_phys=1

net.inet.tcp.blackhole=0
net.inet.tcp.log_in_vain=0
net.inet.tcp.ecn.enable=1
# Maximum number of compressed TCP TIME_WAIT entries
net.inet.tcp.maxtcptw=16384
net.inet.tcp.nolocaltimewait=1

# default size of TCP receive window
net.inet.tcp.recvspace=65535
net.inet.tcp.recvbuf_auto=1
net.inet.tcp.recvbuf_inc=16384
net.inet.tcp.recvbuf_max=131072

# default size of TCP transmit window
net.inet.tcp.sendspace=32768
net.inet.tcp.sendbuf_auto=1
net.inet.tcp.sendbuf_inc=16384
net.inet.tcp.sendbuf_max=131072

net.inet.udp.blackhole=0
net.inet.udp.recvspace=65535
net.inet.udp.maxdgram=57344

net.inet.icmp.drop_redirect=1
net.inet.icmp.log_redirect=1
net.inet.icmp.bmcastecho=0
net.inet.icmp.maskrepl=0
net.inet.icmp.icmplim=100


net.local.stream.recvspace=65535
net.local.stream.sendspace=65535

#net.link.bridge.pfil_onlyip=1
#net.link.bridge.pfil_bridge=0
#net.link.bridge.pfil_member=1

# iface max send queue size
net.link.ifqmaxlen=8192

net.isr.direct=1
# rtsock queue
net.route.netisr_maxqlen=4096
#  IPoE queue
net.isr.defaultqlimit=4096

# mem for dirhash (128Mb)
vfs.ufs.dirhash_maxmem=134217728
# max time in seconds of hash inactivity before deletion in low VM events
vfs.ufs.dirhash_reclaimage=7

# cluster read-ahead max block count
vfs.read_max=256

# Usefull if you are using Intel-Gigabit NIC
dev.em.0.rx_int_delay=200
dev.em.0.tx_int_delay=200
dev.em.0.rx_abs_int_delay=4000
dev.em.0.tx_abs_int_delay=4000
dev.em.0.rx_processing_limit=4096

dev.em.1.rx_int_delay=200
dev.em.1.tx_int_delay=200
dev.em.1.rx_abs_int_delay=4000
dev.em.1.tx_abs_int_delay=4000
dev.em.1.rx_processing_limit=4096
